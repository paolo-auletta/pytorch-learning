# -*- coding: utf-8 -*-
"""Computer Vision Exercise 01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ngW_moe9OC_IHZAfGJbOSrIIfp5LzGtH
"""

import torch
from torch import nn

from torchvision.datasets import EMNIST
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader

import matplotlib.pyplot as plt

from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

# Define device
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load the EMNIST dataset
train_dataset = EMNIST("data",
                       train = True,
                       split = "digits",
                       download = True,
                       transform = ToTensor())

test_dataset = EMNIST("data",
                      train = False,
                      split = "digits",
                      download = True,
                      transform = ToTensor())

# Batch size hyperparameter
BATCH_SIZE = 32

# Define DataLoader
train_dataloader = DataLoader(dataset = train_dataset,
                              batch_size = BATCH_SIZE,
                              shuffle = True) # Better for training

test_dataloader = DataLoader(dataset = test_dataset,
                             batch_size = BATCH_SIZE,
                             shuffle = False) # Better for testing

# Define the CNN model
class CNN(nn.Module):

  def __init__(self, in_channels: int, hidden_units: int, out_channels: int):
    super().__init__()

    self.Layer_1 = nn.Sequential(
        nn.Conv2d(in_channels = in_channels,
                  out_channels = hidden_units,
                  kernel_size = 5,
                  stride = 1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2,
                     stride = 2)
    )

    self.Layer_2 = nn.Sequential(
        nn.Conv2d(in_channels = hidden_units,
                  out_channels = hidden_units * 2,
                  kernel_size = 3,
                  stride = 1),
        nn.Sigmoid(),
        nn.MaxPool2d(kernel_size = 2,
                     stride = 2)
    )

    self.Classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = hidden_units * 2 * 5 * 5,
                  out_features = out_channels)
    )

  def forward(self, x):
    x = self.Layer_1(x)
    # print(x.shape)

    x = self.Layer_2(x)
    # print(x.shape)

    x = self.Classifier(x)
    # print(x.shape)

    return x

# Initialize the model
classes = train_dataset.classes
model_0 = CNN(in_channels = 1, # 1 Color Channel
              hidden_units = 2,
              out_channels = len(classes)).to(device)

# Define loss function, optimizer, and accuracy metric
loss_fn = nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(params = model_0.parameters(),
                             lr = 0.01)

def accuracy_fn(y_pred, y_true):
  correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal
  acc = (correct / len(y_pred)) * 100
  return acc


# Training and testing loop
epochs = 3

for epoch in range(epochs):
  print(f"Epoch {epoch} \n ------------")

  training_loss, training_accuracy = 0, 0

  # Training
  for batch, (x,y) in enumerate(train_dataloader):

    x, y = x.to(device), y.to(device)

    model_0.train()

    # Do the forward pass
    y_logits = model_0(x)
    y_pred = torch.softmax(y_logits, dim = 1).argmax(dim = 1)

    # Calculate the loss (and accuracy)
    loss = loss_fn(y_logits, y)
    training_loss += loss

    training_accuracy += accuracy_fn(y_pred = y_pred,
                                     y_true = y)

    # Optimizer zero grad
    optimizer.zero_grad()

    # Loss backward
    loss.backward()

    # Optimizer step, step, step
    optimizer.step()

  # Scale loss to find the average loss per batch
  training_loss /= len(train_dataloader)
  training_accuracy /= len(train_dataloader)

  print(f"Training Loss: {training_loss:.4f} | Training Accuracy: {training_accuracy:.4f}")

  # Testing
  model_0.eval()
  test_loss, test_accuracy = 0, 0
  with torch.inference_mode():
    for batch, (x,y) in enumerate(test_dataloader):
      x, y = x.to(device), y.to(device)

      # Do the forward pass
      test_logits = model_0(x)
      test_pred = torch.softmax(test_logits, dim = 1).argmax(dim = 1)

      # Calculate the loss (and accuracy)
      test_loss += loss_fn(test_logits, y)
      test_accuracy += accuracy_fn(y_pred = test_pred,
                                   y_true = y)

  # Scale loss to find the average loss per batch
  test_loss = test_loss / len(test_dataloader)
  test_accuracy = test_accuracy / len(test_dataloader)

  print(f"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}")

# Visualize predictions
random_idx = torch.randint(len(train_dataset), size = (1,)).item()
img, label = train_dataset[random_idx]

logit = model_0(img.unsqueeze(0))
pred = torch.softmax(logit, dim = 1).argmax(dim = 1)

plt.imshow(img.squeeze(0).t(), cmap="gray")
plt.title(pred)


# Making a confusion matrix
  # 1. Make predictions with our trained model on the test dataset
  # 2. Make a confusion matrix with `torchmetrics.ConfusionMatrix`
  # 3. Plot the confusion matrix using `mixtend.plotting.plot_confusion_matrix()`

# 1. Make predictions with our trained model on the test dataset
y_preds = []

model_0.eval()
with torch.inference_mode():
  for x, y in test_dataloader:
    # Send the data and targets to target device
    x, y = x.to(device), y.to(device)

    # Do the forward pass
    y_logits = model_0(x)

    # Turn predictions from logits -> prediction porbabilites -> prediction labels
    y_pred = torch.softmax(y_logits.squeeze(), dim = 0).argmax(dim = 1)

    # Put predictions on CPU for evaluation
    y_preds.append(y_pred.cpu())

  # List of predictions into a tensor
  y_pred_tensor = torch.cat(y_preds)

# 2. Setup confuison instance and compare predictions to target
confmat = ConfusionMatrix(task = "multiclass", num_classes = len(classes))
confmat_tensor = confmat(preds = y_pred_tensor,
                         target = test_dataset.targets)

# 3. Plot the confusion matrix
fig, ax = plot_confusion_matrix(
    conf_mat = confmat_tensor.numpy(),
    class_names = classes,
    figsize = (10, 7)
)
