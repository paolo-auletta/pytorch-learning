# -*- coding: utf-8 -*-
"""04 CustomDatasets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c7ZqrcR3-DLFHMWfVZV_1W_uJWuVngQX
"""

# Get data
import requests
import zipfile
from pathlib import Path

# Setup path to a data folder
data_path = Path("data/")
image_path = data_path / "pizza_steak_sushi"

if image_path.is_dir():
  print(f"{image_path} directory already exists, skipping download")
else:
  print(f"{image_path} does not exist, creating one...")
  image_path.mkdir(parents = True, exist_ok = True)

  # Download dataset
  with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
    request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
    print("Downloading data...")
    f.write(request.content)

  # Unzip
  with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
    print("Unzipping data...")
    zip_ref.extractall(image_path)

# Transforming data into tensors
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

device = "cuda" if torch.cuda.is_available else "cpu"

# Converting into dataset
train_transform = transforms.Compose([
    transforms.Resize(size = (64, 64)), # Resize all images to 64x64
    transforms.RandomHorizontalFlip(p = 0.5),
    # transforms.RandomGrayscale(p = 0.5),
    # transforms.ColorJitter(),
    # transforms.RandomRotation(10),
    transforms.ToTensor() # Turn image into a torch.tensor
])

test_transform = transforms.Compose([
    transforms.Resize(size = (64, 64)), # Resize all images to 64x64
    transforms.ToTensor() # Turn image into a torch.tensor
])

train_dataset = datasets.ImageFolder(root = "/content/data/pizza_steak_sushi/train",
                                     transform = train_transform,
                                     target_transform = None)

test_dataset = datasets.ImageFolder(root = "/content/data/pizza_steak_sushi/test",
                                    transform = test_transform)

# Convert into dataloader
BATCH_SIZE = 32

train_dataloader = DataLoader(dataset = train_dataset,
                              batch_size = BATCH_SIZE,
                              shuffle = True)

test_dataloader = DataLoader(dataset = test_dataset,
                             batch_size = BATCH_SIZE,
                             shuffle = False)

# Get class names as list, thanks to ImageFolder module
class_names = train_dataset.classes

# Increased Dropout in Classifier
class CNN(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.Layer1 = nn.Sequential(
            nn.Conv2d(in_channels=3,
                      out_channels=32,
                      kernel_size=3,
                      stride=1),
            nn.BatchNorm2d(num_features=32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.Layer2 = nn.Sequential(
            nn.Conv2d(in_channels=32,
                      out_channels=64,
                      kernel_size=3,
                      stride=1),
            nn.BatchNorm2d(num_features=64),
            nn.ReLU(),
            nn.Conv2d(in_channels=64,
                      out_channels=64,
                      kernel_size=3,
                      stride=1),
            nn.BatchNorm2d(num_features=64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2,
                         stride=2)
        )
        self.Classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(p=0.5),
            nn.Linear(in_features=64 * 13 * 13, out_features=3)
        )

    def forward(self, x):
        x = self.Layer1(x)
        x = self.Layer2(x)
        x = self.Classifier(x)
        return x

model_0 = CNN(3, len(class_names)).to(device)

# Loss function, Optimizer and Accuracy

loss_fn = nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(params = model_0.parameters(),
                            lr = 0.01,
                            weight_decay = 1e-4)

def acc_fn(y_pred, y_true):
  correct = torch.eq(y_true, y_pred).sum().item()
  acc = (correct / len(y_true)) * 100
  return acc

import matplotlib.pyplot as plt
import numpy as np

# Store metrics for visualization
train_losses, test_losses = [], []
train_accuracies, test_accuracies = [], []
total_epochs = []

# Trainig Loop

epochs = 50

for epoch in range(epochs):
  train_loss, train_acc = 0, 0
  total_epochs.append(epoch)
  for batch, (x, y) in enumerate(train_dataloader):
    x, y = x.to(device), y.to(device)
    model_0.train()

    # Do the forward pass
    y_logit = model_0(x)
    y_pred = torch.softmax(y_logit, dim = 1).argmax(dim = 1)

    # Calculate the Loss (and acc)
    loss = loss_fn(y_logit, y)
    train_loss += loss
    train_acc += acc_fn(y_pred, y)

    # Optimizer zero grad
    optimizer.zero_grad()

    # Loss backward
    loss.backward()

    # Optimizer step, step, step
    optimizer.step()

  train_loss /= len(train_dataloader)
  train_acc /= len(train_dataloader)

  train_losses.append(train_loss)
  train_accuracies.append(train_acc)

  # Evaluation
  test_loss, test_acc = 0,0
  model_0.eval()

  for x, y in test_dataloader:
    x, y = x.to(device), y.to(device)

    # Do the forward pass
    y_logit = model_0(x)
    y_pred = torch.softmax(y_logit, dim = 1).argmax(dim = 1)

    # Calculate the Loss (and acc)
    loss = loss_fn(y_logit, y)
    test_loss += loss
    test_acc += acc_fn(y_pred, y)

  test_loss /= len(test_dataloader)
  test_acc /= len(test_dataloader)

  test_losses.append(test_loss)
  test_accuracies.append(test_acc)

  print(f"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%")

# Visualization
epochs_range = range(len(total_epochs))
plt.figure(figsize=(14, 7))

# Loss subplot
plt.subplot(1, 2, 1)
plt.plot(epochs_range, [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_losses], color='lightblue', linestyle='-', linewidth=1, alpha=0.8, label="Train Loss")
plt.plot(epochs_range, [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in test_losses], color='steelblue', linestyle='-', linewidth=1, alpha=0.8, label="Test Loss")
plt.title("Loss Over Epochs", fontsize=16)
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("Loss", fontsize=14)
plt.legend()
plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)

# Accuracy subplot
plt.subplot(1, 2, 2)
plt.plot(epochs_range, [acc.detach().cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in train_accuracies], color='lightcoral', linestyle='-', linewidth=1, alpha=0.8, label="Train Accuracy")
plt.plot(epochs_range, [acc.detach().cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in test_accuracies], color='tomato', linestyle='-', linewidth=1, alpha=0.8, label="Test Accuracy")
plt.title("Accuracy Over Epochs", fontsize=16)
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("Accuracy (%)", fontsize=14)
plt.legend()
plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)

# Add tight layout for better spacing
plt.tight_layout()

# Show the plots
plt.show()

